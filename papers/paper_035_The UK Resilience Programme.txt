Abstract
Objective:
The study aimed to assess the effectiveness of an 18-hr cognitive behavioral group intervention in reducing depressive symptoms (and associated outcomes) in a universal sample of students in mainstream schools in England. The intervention, the UK Resilience Programme (UKRP), was based on the Penn Resiliency Program for Children and Adolescents.
Method:
Students ( N = 2,844; 49% female; 67% White) were ages 11–12 at 16 schools. Classes of students were assigned arbitrarily into intervention (UKRP) or control (usual school provision) conditions based on class timetables. Outcome measures were the Children's Depression Inventory (Kovacs, 1992) (depressive symptoms, primary outcome); Revised Children's Manifest Anxiety Scale (C. R. Reynolds & Richmond, 1985) (anxiety); and child-reported Goodman (1997) Strengths and Difficulties Questionnaire (behavior). Students were surveyed at baseline, postintervention, 1-year follow-up, and 2-year follow-up.
Results:
At postintervention, UKRP students reported lower levels of depressive symptoms than control group students, but the effect was small ( d = 0.093, 95% CI [−0.178, −0.007], p = .034) and did not persist to 1-year or 2-year follow-ups. There was no significant impact on symptoms of anxiety or behavior at any point.
Conclusions:
UKRP produced small, short-term impacts on depression symptoms and did not reduce anxiety or behavioral problems. These findings suggest that interventions may produce reduced impacts when rolled out and taught by regular school staff. We discuss the implications of these findings for policy and for future dissemination efforts.

There are high rates of mental illness in children and young people in the United Kingdom. At any one time, approximately 2% of children age 11–15 and 11% of young people age 16–24 have a major depressive disorder (Green, McGinnity, Meltzer, Ford, & Goodman, 2005). Some authors have found evidence of a recent increase in the rate of emotional problems (Collishaw, Maughan, Goodman, & Pickles, 2004 ; Rutter & Smith, 1995), and the United Kingdom performs poorly in international comparisons (UNICEF, 2007). Mental illness is also associated with impaired functioning, academic and interpersonal difficulties, poor health behaviors, and suicide (Covey, Glassman, & Stetner, 1998 ; Garrison, Jackson, Addy, McKeown, & Waller, 1991 ; Ialongo, Edelsohn, Werthamer-Larsson, Crockett, & Kellam, 1996). Subclinical levels of mental health symptoms may also interfere with functioning and are associated with similar levels of impairment as actual conditions (Gotlib, Lewinsohn, & Seeley, 1995). Poor mental health is one of the strongest predictors of unhappiness in adulthood, stronger than income, marital status, or employment status (Layard, Clark, & Senik, 2012). Childhood and adolescent depression has also been linked to depression in adulthood. Each episode of depression that an individual experiences predicts increased likelihood of recurrence, suggesting that preventing a first occurrence of depression could prevent a large part of the burden in later life (Harrington, Fudge, Rutter, Pickles, & Hill, 1990). Given the economic and social burden of depression and other mental illnesses in adulthood, prevention in childhood could be an important means to improved mental health over the life span. Mental illness in adulthood accounts for 40% of all disability in the United Kingdom, and the estimated cost of anxiety and depression is £12 billion a year (about $19 billion U.S.), including loss of earnings and expenditure on welfare benefits (Layard & Mental Health Policy Group, 2006).
Schools have scope to provide a more effective access point to mental health services for young people than clinics, because of near-universal participation in education (Masia-Warner, Nangle, & Hansen, 2006). In addition, they may be able to prevent the incidence of mental health problems, through targeted or universal programs. A number of programs have been developed to help prevent or treat mild to moderate symptoms of depression, anxiety, and other mental illnesses, which can be delivered in education settings.
Although recent reviews have generally revealed more evidence for targeted programs (implemented with youths at elevated risk for depression) than for universal programs (e.g., Stice, Shaw, Bohon, Marti, & Rohde, 2009), a recent review revealed evidence for both targeted and universal approaches to prevention (Merry et al., 2011). In addition, universal programs are often easier to implement and more popular with schools, partly because of a perceived lack of stigma attaching to participation (Merry et al., 2011 ; Offord, Kraemer, Kazdin, Jensen, & Harrington, 1998). Despite the promise of depression prevention programs, relatively few of these programs have been delivered at scale, using regular school staff and under ordinary conditions (Calear & Christensen, 2010). This is important: Programs that are effective in small samples with a high degree of control from the developers may not work at scale, and there may be considerable difficulties in disseminating programs (Malti, Ribeaud, & Eisner, 2011 ; Weisz & Jensen, 2001).
One program that has been extensively evaluated in research studies but not fully rolled out is the Penn Resiliency Program for Children and Adolescents (PRP), a group intervention that aims to increase resilience and prevent depression through teaching students cognitive-behavioral and social problem-solving skills. The evidence on PRP is mixed: Brunwasser, Gillham, and Kim (2009) presented a meta-analytic review of PRP's effect on depressive symptoms from 17 studies, finding an average effect size of 0.11–0.21 (postintervention to 12-month follow-up) with considerable variation between studies. The largest PRP study reports results for only 697 students. The current study improves on this with 2,844 students included in the analysis, 1,000 of whom were in the intervention group, giving a larger sample than for the 17 past PRP studies combined. The sample is also larger than many similar pragmatic studies (e.g., Calear, Christensen, Mackinnon, Griffiths, & O'Kearney, 2009 ; Malti et al, 2011 ; Stallard et al., 2012), with implementation conditions approaching “real world” conditions, and a follow-up period of 2 years postintervention.
The evaluation of large-scale, real-world implementation of prevention programs is an important next step in mental health research. Programs that are effective in small, tightly controlled studies may be less effective under real-world conditions. Within the literature on depression prevention, for example, the large majority of studies are efficacy studies, in which interventions are delivered by researchers or highly trained providers unaffiliated with the schools or community organizations for which these programs are intended. There are only a few effectiveness studies in which interventions are delivered by endogenous providers (e.g., school teachers and counselors), and these have yielded smaller effects (Stice et al., 2009). There is very little research on the effects of depression prevention programs when implemented by schools on a large scale. A large-scale evaluation of a universal depression prevention program in 50 schools in Australia evidenced no significant short- or long-term benefits on students' depressive symptoms (Sawyer, Harchak, et al., 2010 ; Sawyer, Pfeiffer, et al., 2010). It is promising that a recent meta-analysis of PRP studies revealed significant effects in both efficacy and effectiveness studies (Brunwasser et al., 2009), although PRP has not previously been evaluated when disseminated on a wide scale.
We evaluated the effects of a UK adaptation of PRP (UK Resilience Programme [UKRP]) that was delivered in 16 schools. We hypothesized that program completion would be high, with student attendance at UKRP sessions higher than for many previous trials because of its embedding within the school curriculum. On the basis of previous efficacy and effectiveness findings, we hypothesized that UKRP would reduce symptoms of depression relative to the control group. We also examined UKRP's effects on secondary outcomes that often co-occur with depression, including anxiety and behavior problems.
Method
Participants
Schools
Three Local Authorities (LAs; local governments responsible for delivery of public services, including many schools) were recruited during 2006 to participate in this evaluation of UKRP. These three regions were geographically dispersed and demographically varied, a deliberate strategy to trial UKRP in different contexts; see Table 1 for details of each area. Overall, our sample of schools and students was more deprived than the average for England; 25% of our sample was eligible for free school meals (FSM) compared with an eligibility rate of 13% among pupils at all secondary schools in England in January 2007 (Department for Children, Schools and Families [DCSF], 2007). Our sample also overrepresented ethnic minority students; 33% of our sample was non-White, whereas for all state secondary school students in 2007 in England, the figure was 17% (DCSF, 2007). These differences reflected the characteristics of the schools that chose to run the program.
undefined undefined
Table 1 Participating Local Authorities (LAs)
undefined undefined
Table 1 Participating Local Authorities (LAs)
LAs recruited schools from among their secondary schools. Of the 45 schools invited, 22 schools (49%) agreed to participate in the UKRP intervention and evaluation, on the understanding that they would be able to provide students for both the intervention group and the control group. However, six of these schools failed to provide an appropriate control group and so were excluded from the study. This left 16 schools with both intervention and control conditions.
Students
Evaluation participants were students beginning their secondary school enrolment at one of the 16 UKRP schools in September 2007 in the relevant cohort (grade level). Almost all students (over 99%) were age 11.0–12.0 years at the start of the academic year in September 2007.
Study Conditions
Condition assignment
We were not able to randomize classes into intervention or control groups because of timetabling constraints and the limited number of school staff trained to teach UKRP. Within each school, classes of students from the relevant cohort were assigned to UKRP or a control condition. Schools were responsible for the assignment, with oversight from the research team. In order for a class to be able to participate in UKRP workshops, there had to be enough classrooms available at the right time (when the class was scheduled to have the lesson UKRP would replace), and there had to be a trained facilitator available to teach it. Facilitators, particularly those who were subject teachers, had a busy timetable of other lessons to teach, leaving little flexibility in when they were available to teach UKRP.
Intervention assignment was therefore not random, but, conditional on class membership, it was arbitrary and largely unrelated to student characteristics, particularly mental health. There were few slots available when facilitators could teach UKRP, and whichever classes were available at the time were assigned to the intervention. Students were assigned to classes and timetables were finalized by July 2007, before students joined these schools in September 2007. As a result, schools had limited information about students when they planned class membership and timetables. Schools had basic demographic information about students (e.g., gender and ethnicity) and information about their prior academic attainment, but were unlikely to have had any information about mental health status. In 10 schools, teachers used software to generate class assignments for new students, aiming to create classes that were demographically and academically mixed. This meant that most classes within these schools looked similar in terms of gender, ethnicity, FSM eligibility, and prior attainment, because these were the factors taken into account at assignment. However, six schools used academic setting, assigning students to classes by academic ability. Three of these schools therefore included classes from different academic levels in the intervention group to ensure that UKRP students had similar characteristics to control group students. The remaining three schools assigned classes of above-average academic ability to the intervention, generating a difference in average academic attainment between the intervention and control groups. Although most schools assigned classes arbitrarily to intervention, we know that two schools deliberately selected students into the intervention condition because of concerns about their emotional well-being or behavior, withdrawing them from their timetabled classes. We cannot be sure of the exact number, but there were approximately 45 intervention students selected in this way.
We address these potential threats to the validity of the experimental design in three ways. First, we examine intervention effects on the basis of the original class assignment before facilitators had met students. Second, we covary the outcome score at baseline in all our analyses and include controls for prior academic attainment and demographic characteristics. Third, we present a robustness check, in which we have excluded the schools that we know selected students for UKRP on the basis of perceived need. Because class was the unit of condition assignment, all analyses take the clustered structure of the data into account.
Schools differed in the proportion of this new cohort they were able to include in the intervention, with the proportion ranging between 11% and 84% of the cohort, but with the majority of schools (12 out of 16) including between 25% and 52%. The smallest number of workshop classes in a school was two, and the largest number was 12, with 10 of the 16 schools running between four and seven workshop groups. There was also considerable variation in the size of the cohort: the smallest contained about 60 students, and the largest 300. Because of these two factors (cohort size and the proportion of the cohort assigned to UKRP), the number of workshop students and control group students differed between schools, and we control for school at baseline in our analyses to account for this and other differences between students attending different schools.
UKRP
Curriculum and structure
The PRP is a curriculum developed by a team of psychologists at the University of Pennsylvania (see Brunwasser et al., 2009, for a summary of the program and previous PRP research). Its original aim was to prevent adolescent depression, but it now aims more broadly to build resilience and promote realistic thinking and adaptive coping. The curriculum teaches cognitive-behavioral and social problem-solving skills. Central to PRP is Ellis's (1962) Activating event-Belief-Consequences model, that beliefs about events mediate their impact on emotions and behavior. PRP participants are encouraged to identify and challenge unrealistic beliefs, to use evidence to make more accurate appraisals of situations and of others' behavior, and to use effective coping mechanisms when faced with adversity. Participants also learn techniques for positive social behavior, assertiveness, negotiation, decision making, and relaxation. A range of teaching methods and materials are used, including class discussion, worksheets, and games. The UKRP is the 18-hr UK implementation of PRP, with minor changes in examples and adaptations made for vocabulary. Appendix sets out the table of contents for UKRP.
Schools had been asked to find 18 hr in their students' class timetables for each set of workshops, but the length of each session and the time gap between sessions depended on each school's timetable. The majority of schools (12 of 16; 75%) had lesson slots of 1 hr's duration, and so split the program across 18 sessions. Of the remainder, two schools had 50-min sessions; one school had 80-min sessions; and one school had 100-min sessions. The frequency of sessions also varied: nine schools scheduled one workshop per week; six schools scheduled one workshop per fortnight; and one school scheduled three workshops per fortnight.
The size of UKRP workshop groups also varied. The developers of PRP recommended that it be taught in groups of 15 or fewer; because most secondary school classes have about 30 students, this meant splitting classes in two for UKRP. Group size ranged between five and 18, while the mean group size was 13.5. Forty of 78 workshop groups (51%) contained 14 or 15 students, and only 11 groups (14%) had more than 15 students.
Intervention facilitators
The purpose of the study was to test whether UKRP could be delivered in the real world, with the staff and facilities ordinarily available to schools. Thus, the intervention was taught by school staff rather than by university researchers or mental health professionals. Intervention teachers (“facilitators”) were unlikely to be familiar with cognitive-behavioral therapy (CBT) or with programs similar to UKRP and required training. This limited the number of facilitators available to teach, and therefore the number of students who could receive the intervention. Participating schools were allocated training places by their LA and were asked to find appropriate staff. Selection procedures varied by school. In some schools, senior managers invited only selected individuals, whereas in others, all staff members were invited to apply with senior managers selecting from among the applicants. This reflects how schools ordinarily select staff for similar opportunities. Once selected, future facilitators registered and were asked to complete Resilience Online—an online positive psychology program covering core cognitive concepts and skills from CBT and encouraging reflection on the user's own emotional responses and behavior. Resilience Online contains eight modules that each take approximately 45–65 min to complete. Module completion was not monitored, but 44 of 48 facilitators logged on and covered at least some of the program. Facilitators received 10 days of training in Philadelphia (USA) from July 23 to August 3, 2007. 1 Due to cancelled flights, 23 facilitators from one LA arrived late and received about 2 days less of training time. These teachers taught 37 workshop groups, 48% of the 78 groups covered by this evaluation. The first week of training focused on learning about CBT and “adult-level” skills, with the second week focusing on the UKRP curriculum and practicing delivering workshops.
The majority of facilitators were school teachers, who ordinarily taught specific academic lessons such as English, mathematics, humanities, and the like. Other staff included learning mentors, teaching assistants, local authority staff, and one school nurse. There were 48 facilitators in this evaluation, teaching 78 workshop groups, the majority of whom were school-based staff (see Table 2), and the majority of whom taught workshops alone. Team teaching was also typically used when facilitators were school support staff rather than teachers, and lacked experience working with groups of students.
undefined undefined
Table 2 Facilitators and Workshop Groups
undefined undefined
Table 2 Facilitators and Workshop Groups
During implementation, facilitators were invited to participate in phone-based support groups that met (by conference call) once every 2–4 weeks. The purpose of these groups was to provide support, to help prepare for upcoming lessons, to discuss questions about implementation, and to share experiences and recommendations. Each group was led by a member of the PRP team who provided the initial training. Facilitators were divided into seven groups on the basis of their schedules; each group included facilitators from different schools, with facilitators from the same school in the same group. There were nine sessions in total: Only six facilitators attended eight or nine sessions, but 31 (65%) attended at least five out of nine sessions, and only two attended no sessions at all.
Control group
UKRP was fitted into an already full school timetable. This meant that 18 hr of lessons were replaced by UKRP for students in the intervention group, whereas control group students continued to receive usual school provision. Table 3 sets out the lessons that UKRP replaced. The most commonly replaced lesson was Personal, Social and Health Education (PSHE), or a similar lesson. PSHE is usually taught for 1 hr a week in secondary schools. There is no standard curriculum, and content and teaching style vary substantially, but lessons usually cover the following: emotional and physical health and well-being; sex and relationships; drugs, alcohol, and tobacco; personal finance; careers; and study skills (Formby et al., 2011). UKRP covers similar content to parts of the PSHE curriculum, so it is not surprising that 13 schools used this lesson slot. Three schools replaced academic lessons with UKRP.
undefined undefined
Table 3 Lesson That UKRP Replaced in Students' Timetables (Usual School Provision Received by Control Group)
undefined undefined
Table 3 Lesson That UKRP Replaced in Students' Timetables (Usual School Provision Received by Control Group)
Main Outcome Measure
Depressive symptoms
Depression was measured using the Children's Depression Inventory (CDI; Kovacs, 1992), a self-reported symptom checklist. Symptoms relate to negative mood, interpersonal problems, ineffectiveness, anhedonia, and negative self-esteem. Children indicate whether they have experienced these symptoms over the previous 2 weeks. Higher scores indicate higher levels of depressive symptoms, and the scale has been shown to be valid and reliable in measuring the severity of depressive symptoms (Kovacs, 1992 ; W. M. Reynolds, 1992). The CDI was used in most previous PRP research (Brunwasser et al., 2009). The full version contains 27 items, with a total score range of 0–54; we omitted Item 9 on suicidal ideation, so scores range from 0 to 52. In tables of descriptive statistics, we present the raw CDI score, whereas for the regression analyses, we have standardized the score to have a mean of 0 and a standard deviation of 1, using the baseline mean and standard deviation of the full sample (intervention and control groups pooled). This allows for easier interpretation in terms of effect sizes. Because the raw and standardized CDI scores are highly skewed (skewness = 1.26 at baseline), we conducted a robustness check running the same analyses on the (standardized) square root of the CDI score, which makes the initial distribution of CDI scores look more normal (baseline skewness = −0.05).
Secondary Outcome Measures
Anxiety
Anxiety was measured with the Revised Children's Manifest Anxiety Scale (RCMAS; C. R. Reynolds & Richmond, 1985), a self-report checklist of symptoms relating to physiological anxiety, worry, oversensitivity, social concerns, and concentration problems. The 28 items that measure anxiety are scored 0 or 1 (no/yes responses to items), giving a score range of 0–28. High scores indicate more severe symptoms, and the scale has been shown to have good reliability and validity (C. R. Reynolds & Richmond, 1985). As for the CDI score, we present raw RCMAS scores as descriptive statistics but use the standardized variable in regressions to allow for easier interpretation of effect sizes.
Behavior problems
Behavioral symptoms were measured using the self-report version of the Goodman Strengths and Difficulties Questionnaire (SDQ; Goodman, 1997). The SDQ total difficulties score comprises 20 items, each scored 0, 1, or 2 according to the perceived severity of the symptom. This gives a minimum possible score of 0 and a maximum of 40, with higher scores indicating more (and more severe) symptoms. There are four five-item subscales that sum to give the total score: emotional symptoms, conduct problems, hyperactivity/inattention, and peer relationship problems. We examined the total score as well as the Internalizing and Externalizing subscales separately.
Workshop quality
We collected three possible indicators of workshop quality (see Table 4). First, UKRP lessons should be taught in groups of 15 pupils or fewer, so we used the number of pupils assigned to each workshop group as an indicator of quality. Second, schools should have devoted at least 18 hr to the UKRP lessons, so we used the time scheduled by the school for UKRP lessons as the second quality indicator. Third, PRP trainers were asked to score UKRP facilitators along four dimensions: understanding of core concepts; engagement in training; clarity in communicating curriculum concepts; and ability to make curriculum come alive when teaching. Trainers rated each dimension on a 1–3 scale, where 1 was cause for concern , 2 was satisfactory , and 3 was outstanding . The four scores were then summed. Responses were obtained from 14 trainers, who provided ratings for facilitators they had worked with and knew well enough to provide a score for—the number of scores available for each facilitator therefore varied. The final score for each facilitator is the mean of all trainers' scores available. One or more trainer scores were available for 46 of 48 facilitators. To calculate a total quality score, we calculated z scores of the three quality measures (number of pupils in the workshop group [reversed scored]; scheduled workshop time; and trainer rating of UKRP teacher) and took the mean of these. When the trainer score is missing, this variable takes the value of the mean of the z scores of the number of pupils in the group and the scheduled workshop time. 2 A higher score indicates higher quality.
undefined undefined
Table 4 Summary of Workshop Quality Measures
undefined undefined
Table 4 Summary of Workshop Quality Measures
Program completion
We examined the hours of workshops received and student absence.
Procedure
The trial was funded by DCSF (now the Department for Education), responsible for school-level education policy in England. Ethical approval was granted by DCSF. Figure 1 presents a flowchart of the recruitment and retention of participants in the evaluation.
undefined Figure 1.
Figure 1.
Flowchart of the recruitment and retention of participants in the evaluation.
Consent for participation in the evaluation was sought from both parents and students. First, schools wrote to parents giving information about the intervention and evaluation and offering them an opt-out for the evaluation, using text agreed by DCSF and the research group. Very few parents chose to opt out. We cannot be sure of the exact numbers because schools managed this process and did not always report reasons for questionnaire nonresponse. Students could themselves choose not to fill in questionnaires, and could decide on the day of the survey. All students in the intervention group participated in UKRP workshops unless they left the school, were long-term absent, or moved to another (control) class, as the program itself was incorporated into the school curriculum and was therefore not optional. Participants were not blinded to condition allocation.
Students were surveyed at baseline and at follow-up points, unless they were absent, chose not to complete the questionnaires, or had left the school. UKRP was taught during the 2007–2008 academic year only. There were four main data collection points: at baseline (September–October 2007); postintervention (between February and June 2008, depending on the school); 1-year follow-up (June 2009); and 2-year follow-up (June 2010). 3 Surveys were completed in classrooms during normal lesson times and administered by a teacher not involved with UKRP. Once finished, students placed their questionnaires in envelopes and sealed them, and the envelopes were returned to the research team. Students were informed beforehand that their responses were confidential, but that if the researchers were worried about them, they would contact the school. The research team contacted schools about students who reported high levels of depression (CDI ≥ 19) or anxiety symptoms (RCMAS ≥ 20) based on standardization sample norms (Kovacs, 1992 ; C. R. Reynolds & Richmond, 1985) or who made comments about bullying, violence, or other child protection issues. Schools responded to these concerns according to their own policies.
Schools administered postintervention questionnaires to students (both intervention and control) within 2 weeks of finishing a set of workshops. Most schools began teaching UKRP in September 2007, and all had started by the end of October 2007. This meant that the time between the baseline assessments and the start of workshops was short for the majority of the intervention group. However, seven schools that finished their first series of workshops early in the academic year (February–March 2008) started a second set of workshops that lasted until June 2008. Students in these workshop groups therefore experienced a longer gap between the baseline measure in the autumn of 2007 and the start of workshops in February–March 2008. Because of these differences in starting date, duration, and timing, UKRP workshops finished at different times, and so students completed the postintervention measures between February and June 2008. We know the dates when questionnaires were completed, and we include a survey month dummy in regressions in order to control for any seasonal, age, or timing effects.
Statistical Analyses
Power
The required sample size was calculated to detect a postintervention effect size of 0.2 with power of 0.8 (α = .05, two-tailed, and a correlation of .6 between pre- and postintervention CDI scores. We also allowed for the impact of clustering, as condition assignment was at the class level, with an intraclass correlation in CDI scores of 0.06 and an average class size of 30. These numbers came from a pilot data collection carried out in eight of the schools in July 2007, with the cohort 1 year older than the evaluation cohort. This suggested a need for 75 clusters of 30 students, or 2,250 students across 12–13 schools. With 16 schools in our sample, more than 2,800 students, and allowing for attrition (which was lower than expected), we therefore had sufficient power when the minimum detectable effect size needed was 0.2. However, the study was underpowered to detect effect sizes smaller than this. Note that although classes of 30 students formed the unit of assignment to intervention or control conditions, UKRP classes would then be split in two to form workshop groups (15 students), whereas control classes were taught in groups of 30.
Baseline differences and attrition
We tested for baseline differences using ordinary least squares regression, with condition assignment predicting the value of outcome measures and demographic variables at baseline. We also report a second version of each regression that includes school dummies. We clustered the standard errors of all regressions by class grouping (unit of condition assignment) and report the p value of the coefficient on condition assignment.
We calculate attrition statistics on the basis of the sample of students for whom we have baseline data, that is, students who we know were in one of the UKRP schools at baseline and were available and willing to complete a survey. Logistic regression was used to examine whether student characteristics, including intervention assignment, predicted attrition. All students for whom baseline data wereavailable were included, and regressors used were the CDI score at baseline, RCMAS score at baseline, gender, special educational needs (SEN) status, free school meal (FSM) entitlement, ethnicity, prior attainment in English and mathematics, school at baseline, and an intervention assignment dummy, which was also interacted with each of the other variables.
Outcomes
Analyses of the intervention impact on the CDI, RCMAS, and SDQ scores included all students with baseline data and data for (at least) one follow-up period (postintervention, 1-year follow-up, and 2-year follow-up). Thus, our analyses do not include the approximately 2.3% of participants who did not complete any assessments beyond baseline. This approach is used in many studies reporting “intent-to-treat” analyses (e.g., regression, growth curve analyses) that require two data points to estimate a participants' trajectory on an outcome measure over time (e.g., Streiner & Geddes, 2001).
We chose not to estimate or impute missing data for participants who had only completed the baseline assessment because of the small proportion of participants affected (imputation procedures are most helpful in preserving power and reducing bias when rates of attrition are high) and because imputation procedures can introduce their own problems and biases (e.g., Streiner, 2002 ; Streiner & Geddes, 2001). Importantly, intervention condition was evaluated on the basis of allocation to condition, and we did not exclude any participants on the basis of low intervention dosage or failure to complete the intervention.
Ordinary least squares regression in Stata 12 was used to assess the impact of the intervention at each follow-up point, by regressing the follow-up intervention score on the baseline score and study condition. Because class was the unit of condition assignment, we clustered the standard errors for all analyses by class grouping. We included several control variables in order to demonstrate the robustness of our results despite the nonrandom condition assignment. Controls included the surveying month; student characteristics (gender; FSM entitlement; special educational needs status; ethnicity; prior academic attainment), and the school attended at baseline. Control variables were entered as dummies. Intervention impacts at different time periods were assessed in separate regressions so that we could examine immediate and longer term effects separately and for ease of comparison with other depression prevention trials in which short-term and long-term effects have been examined separately (e.g., Rivet-Duval, Heriot, & Hunt, 2011 ; Roberts, Kane, Bishop, Matthews, & Thomson, 2004 ; Roberts, Kane, Thomson, Bishop, & Hart, 2003 ; Sawyer, Harchak, et al., 2010 ; Sawyer, Pfeiffer, et al., 2010 ; Spence, Sheffield, & Donovan, 2003). Because this is one of the first studies in which the effectiveness of UKRP has been examined when implemented on a wide scale, we erred on the side of detecting (rather than overlooking) possible intervention effects. In the spirit of this exploration, we report conventional and uncorrected levels of significance ( p < .05) rather than controlling for the number of analyses.
Because the effects of depression prevention programs have often varied by gender and by initial symptom level (e.g., Garber & Downs, 2011 ; Stice et al., 2009), we also tested whether intervention effects were moderated by these variables by conducting additional analyses, including Baseline Score × Intervention or Gender × Intervention interactions.
Intervention quality and outcome
To examine whether intervention quality was related to outcome, we conducted a regression analysis predicting depressive symptoms across the post- and follow-up assessments from condition, with condition split into “high quality” (quality score at or above the median), “low quality” (quality score below the median), or control groups. We also conducted a regression analysis to examine whether the intervention quality score predicted improvements in depressive symptoms within the intervention condition.
Robustness checks
All three outcome variables were skewed, so we conducted additional outcome analyses predicting square-root transformed scores. Because we knew which schools undermined arbitrary condition assignment (by specifically targeting students with social and emotional difficulties), we excluded these schools as an additional robustness check.
Results
Baseline Comparisons
Table 5 presents demographic and outcome variables at baseline for the intervention and control groups, along with the p values of tests of equality of the two group means (clustered by intervention assignment). Intervention and control groups had similar depression, anxiety, and behavior scores at baseline, and no significant differences in gender or age. However, intervention group students had significantly higher prior academic attainment in English than control group students. The differences in academic attainment remained when we control for school at baseline, suggesting that within schools, UKRP students were more likely to be high attaining than those in the control group. We know that the difference in attainment resulted because assignment was at the class level; six schools formed classes on the basis of prior academic attainment, and three of these assigned a disproportionate fraction of high-attaining classes to the intervention condition. As mentioned in the Method section, analyses controlled for student characteristics, including prior academic achievement.
undefined undefined
Table 5 Descriptive Statistics at Baseline by Condition Assignment
undefined undefined
Table 5 Descriptive Statistics at Baseline by Condition Assignment
Attrition
Figure 1 shows the recruitment and retention of student participants in the evaluation. All schools that undertook baseline assessments in autumn 2007 remained in the trial until 2-year follow-up. The withdrawal rate by parents was low: In 2007–2008, fewer than five students were withdrawn by their parents; at 2-year follow-up, this had increased to about 15 students. Up to about 5% of the cohort decided not to complete the surveys at any given assessment point. However, the large majority of students chose to complete the inventories, as evidenced by the low attrition rate. As a result, there was very little selection generated by opting out of the evaluation, and the major reasons for incomplete questionnaires were student absence and mobility across schools. Overall, 2% of the intervention group and 3% of the control group were not included in analyses because they did not have any data beyond baseline, or 2.3% of the sample overall.
At postintervention, students were significantly more likely to be missing data if they had SEN ( p = .013), or if they had a higher CDI score at baseline ( p = .018). Intervention assignment did not have any significant impact on the likelihood of missing data, nor did the interactions of intervention assignment with any other variable. At 1-year follow-up, students with high prior attainment in English tended to be less likely to have missing data ( p = .07). At 2-year follow-up, SEN ( p = .025) and high CDI scores at baseline ( p = .003) again predicted missing data, as did entitlement to FSM ( p = .012). SEN ( p = .023), higher CDI scores at baseline ( p = .006), and entitlement to FSM ( p = .024) all significantly increased the probability of having missing data from at least one of the postbaseline assessments, whereas high attainment in English tended to decrease the probability ( p = .071). Students with SEN who were in the intervention group were more likely to have missing data ( p = .047). However, there was no main effect of study condition in any of our specifications, and this was the only significant interaction with condition assignment at any point, so we do not believe that there was a significantly different probability of attrition caused by study condition. Rather, differences in attrition rates seem to be due to student characteristics such as SEN, FSM entitlement, baseline CDI scores, and prior academic attainment. Given that most missing data were due to student absence and that this is higher for SEN and FSM students (DCSF, 2009), these results are not surprising. In our analyses below, we control for these student characteristics.
Program Completion and Attendance
The UKRP curriculum was designed for a minimum of 18 hr of workshops, but students may have received less time because the school allocated less time to the program, or because of student or teacher absences. Not all groups covered the full curriculum. We were not able to measure curriculum coverage or teacher absence, but we do have information on the amount of time schools allocated to UKRP and on student absence. Of the 78 workshop groups in the evaluation, 47 (60%) were timetabled for 18 hr of lessons; 13 (17%) had more than 18 hr allocated; and 18 (23%) had less than 18 hr. The amount of time available ranged between 10 hr and 25 hr, with 95% of workshops (74 groups) having between 15 and 22 hr. When less than 18 hr was available, this was because the time was needed for other lessons, because schools set a low priority on UKRP, or because of external constraints such as public holidays or professional development days—in one case only was it due to the facilitator of the group disliking UKRP and choosing not to continue. When more than 18 hr were available, this was often compensation for the slow progress of students with low academic attainment. Student absence or changes of class or school also reduced the intervention dosage. Because workshops were scheduled during ordinary school time, we would expect attendance to be high, as by law students of this age must attend school. We have data available on the attendance of 836 students (84% of intervention students) from 66 of 78 workshop groups (85% of workshop groups). Of these 836 students, 85% (709 students) attended at least 14 hr of workshops, 60% attended at least 17 hr (505 students), and 38% (318 students) attended 18 hr or more. Of the 15% (127 students) who attended less than 14 hr of workshops, 65% (82 students) were in workshop groups that had fewer than 16 hr scheduled, so that any individual absences would have resulted in low program hours. Of the remaining 45 students with attendance below 14 hr, 31% were at a school that undermined condition assignment by encouraging certain intervention students (those who facilitators believed had no emotional or behavioral difficulties) to move to a control class occurring at the same time, resulting in very low program completion for these students. The minority of students received the full 18 hr of workshops (38%), yet the absence rate was low compared with similar PRP trials. For instance, Gillham et al. (2006) reported 45% of students attending at least 88% of sessions, whereas in our study, 76% of students attend this amount. The major reason for this was probably that UKRP was scheduled during the school day, whereas Gillham et al. used an after-school time slot. Very low program dosage was mainly due to schools providing less time for lessons, or to facilitators' deliberate manipulation of study condition. In the analysis below, we do not account for intervention dosage, because this will have been endogenously determined. Moreover, our aim is to test the impact of the program as it would be “on the ground,” and problems of timetabling and absence are likely to reduce the impact of interventions once rolled out.
Outcomes
Table 6 presents raw means, standard deviations, and sample sizes for each outcome variable at each data collection point. We report results of regression analyses below and in Table 7.
undefined undefined
Table 6 Means and Standard Deviations for the Outcome Measures at Baseline and Follow-Up Points
undefined undefined
Table 6 Means and Standard Deviations for the Outcome Measures at Baseline and Follow-Up Points
undefined undefined
Table 7 Intervention Impact
undefined undefined
Table 7 Intervention Impact
Depressive symptoms
We found no impact of condition when all follow-up periods were combined. We found a small but statistically significant ( p < .05) effect of condition at postintervention (because a higher CDI score indicates worse mental health, the negative coefficient on “intervention impact” suggests an improvement in UKRP relative to control). The CDI score used here is standardized to have a mean of 0 and a standard deviation of 1, so we can interpret the program impact at postintervention to be 0.093 of a standard deviation in size (95% CI [−0.178, −0.007], p = .034). At 1-year and 2-year follow-ups, there was no impact of the intervention (1-year effect size = 0.008, 95% CI [−0.075, 0.092], p = .84; 2-year effect size = 0.040, 95% CI [−0.063, 0.142], p = .44). This suggests that the UKRP workshops may have had an impact on students' depressive symptoms in the short run (postintervention), but by 1-year follow-up, this had disappeared. The interactions of condition with baseline score and with gender were not statistically significant.
Anxiety
There was no significant intervention effect on anxiety symptoms (RCMAS score). The interactions of condition with baseline score and with gender were not statistically significant.
Behavior problems
There was no significant intervention effect on behavior problems (SDQ total score). There also was no intervention effect on Internalizing and Externalizing subscales (details not shown). The interactions of condition with baseline scores and with gender were not statistically significant.
Impact by intervention quality
As can be seen from Table 8 (column 1), participants in high- (but not low-) quality groups tended to report lower levels of depression symptoms than controls following the intervention. The difference in coefficients for high-quality versus low-quality groups was significant, F (1, 112) = 4.74, p = .0316. As can be seen in Table 8 (column 2), intervention quality score predicted improvements in depressive symptoms within the intervention condition. The significant negative coefficient for the quality score suggested that intervention pupils in higher quality workshop groups experienced greater declines in their CDI scores than pupils in lower quality workshop groups (effect size = 0.046, 85% CI [−0.082, −0.010], p = .013). Similar patterns are seen when the RCMAS and SDQ scores are the outcomes, but the coefficients on the high-quality workshop condition (relative to the control group) are not significant, and coefficients on the high- and low-quality workshops are not significantly different from each other: RCMAS, F (1, 112) = 3.62, p = .06; SDQ, F (1, 112) = 3.22, p = .08.
undefined undefined
Table 8 Intervention Impact by Intervention Quality
undefined undefined
Table 8 Intervention Impact by Intervention Quality
Robustness checks
Analyses predicting square-root-transformed scores for the three outcomes yielded similar findings to those reported above. Analyses excluding students who were known to have been targeted by schools because of social and emotional difficulties produced similar findings to those reported above.
Discussion
Our results suggest that the scaled-up UKRP had a small and short-lived impact on students' symptoms of depression. Our results on depressive symptoms at postintervention match those reported in Brunwasser et al. (2009), who found an impact of 0.11 standard deviations in a meta-analysis of 17 PRP studies. However, we found no impact on depressive symptoms at 1- or 2-year follow-up, whereas Brunwasser et al. found a significant impact of 0.20 standard deviations at 1-year follow-up (10 studies). This discrepancy may reflect differences in the impact of targeted versus universal programs. In the review by Brunwasser and colleagues, six of 10 studies with 1-year follow-up data were conducted with targeted (high-risk) samples. It is common for universal prevention programs to find smaller impacts than targeted programs (Merry, McDowell, Hetrick, Bir, & Muller, 2004 ; Stice et al., 2009). One reason for this could be that most students drawn from a universal sample already have good mental health and do not need the skills and support provided by the workshops. Recent research suggests that PRP is most beneficial for students with elevated levels of hopelessness—a cognitive risk factor for depression that is targeted by the intervention (Gillham et al., 2012). Because we were unable to measure risk factors targeted by the intervention, we do not know whether some subgroups benefitted substantially. Another reason might be a lack of sensitivity in the measures we are using. For example, the CDI (our primary outcome measure) provides a scale ranging from 0 to 52 to assess the severity of depressive symptoms, yet at baseline, 60% of students in our sample scored 8 or below (average or below-average levels of symptoms), and 12% scored 0 or 1. Only 6% scored above 19, indicating significant symptoms of depression. Because of this, we encounter a strong floor effect: Students without many symptoms and with low risk of depression do not have much room for improvement. Given the UKRP's focus on promoting resilience broadly and promoting adaptive thinking and coping, measures of these intervention targets and measures of positive indicators of well-being might better capture the intervention's effects when delivered universally. Consistent with this, a recent evaluation of a universal school-based depression prevention program revealed significant benefits on self-esteem and coping skills, though not on depressive symptoms (Rivet-Duval et al., 2011).
It is also common for dissemination studies of prevention programs to reveal smaller effects than efficacy trials, which tend to have smaller sample sizes, use more experienced group leaders, and maintain tighter control over intervention quality (Malti et al., 2011). In addition, in our study we examined data from facilitators' first year of UKRP teaching: They had no previous experience with such interventions, and it is plausible that their skills could improve with experience, perhaps resulting in greater program impact in the future. We did not measure the quality of intervention implementation directly, but dosage was high, with 60% of students attending at least 17 hr of workshops. This compares favorably with some previous depression prevention interventions (Calear et al., 2009 ; Gillham et al., 2006 , 2007). When we use a measure of the quality of program inputs—made up of the number of students in a group, the number of hours scheduled for the program, and the trainer ratings of UKRP facilitators—we find that higher quality workshop groups are associated with significantly lower CDI scores. Thus although we cannot compare the quality of the intervention with the quality of interventions in other studies, within our sample, the higher quality workshops were associated with better results.
Trials conducted by independent researchers may also produce smaller effect sizes than those carried out by the research team that developed the intervention. This could be due to the smaller sample sizes of developer-led trials, higher program fidelity when the development team is involved, or unintended bias from researchers who are motivated to achieve positive results (Eisner, 2009 ; Petrosino & Soydan, 2005). The current study was designed and carried out by an independent research team (albeit with advice from the program developers), and the implementation received less developer support than most previous PRP studies. Programs may also be less effective when delivered by school staff rather than by specialists (Calear & Christensen, 2010), yet using school staff is more likely to be sustainable. These findings suggest that greater attention should be paid to the dissemination process. The dissemination model used in this study places a heavy emphasis on the initial training period, with relatively few hours devoted to ongoing support during implementation. Recent research suggests effective dissemination of treatment and prevention programs may require more intense supervision and support while group leaders are delivering interventions (Lochman et al., 2009). Standardized intervention components (e.g., using video, computer, and other media) may also help to ensure delivery of key components (Connor-Smith, Jensen, & Weisz, 2002). Interventions that require intensive training and supervision (and small-group delivery) may not be feasible for many schools. It will be important to identify and develop dissemination and implementation practices that can efficiently promote the effective implementation of UKRP.
It is also worth considering what UKRP was compared with: The control group received usual school provision, usually PSHE lessons. Because PSHE addresses issues such as emotional health, we are in effect comparing an alternative intervention; this could reduce our ability to find effects of the intervention, and could help explain differences in the results between this study and other evaluations of the PRP curriculum (e.g., Chaplin et al., 2006). In addition, UKRP was taught in classes about half the ordinary size (around 15 students), whereas the usual school provision was in classes of 30. We are therefore unable to disentangle the effects of increased attention and support from the impact of this specific curriculum, unlike other studies that included attention control conditions (e.g., Stallard et al., 2012). Studies in which interventions are compared against attention controls may produce smaller effect sizes (Calear & Christensen, 2010). However, the decision about whether or not to adopt UKRP in schools should be based on whether it is more or less effective than current school provision, so this does seem like the appropriate comparison to make (Roland & Torgerson, 1998).
Strengths of the study include the large sample size; the long follow-up period; the inclusion of a large number of schools from three different regions (increasing the external validity of the results); excellent response rates and low attrition; and the use of reliable and valid measures of depression, anxiety, and behavioral symptoms. The trial was also a realistic pragmatic implementation of PRP, using school staff rather than mental health professionals.
One major limitation is the lack of randomization in condition assignment, and we might question whether the arbitrary assignment produced an appropriate control group. Apart from a few cases in which teachers manipulated the composition of UKRP groups, intervention and control groups look similar. However, classes assigned to the intervention tended to have significantly higher levels of academic attainment. This may have occurred by chance in some cases, but facilitators may also have felt that the program would be easier to teach to higher attaining classes or that low-attaining classes could not spare lesson time for a nonacademic subject. The assignment of students to intervention or control within the same cohort could also have resulted in spillovers. Positive spillovers from intervention students would bias downwards the estimate of the effect of the program, as the control group would receive a partial intervention.
Conclusions
We find a statistically significant, but small and short-lived reduction in depression symptom scores in a large-scale implementation of the Penn Resiliency Program in English secondary schools. There was no significant impact on anxiety scores or on self-reported behavior. Higher quality implementations of the program were associated with greater reductions in depression symptoms. Program attendance was high, and there was no suggestion that the program was not acceptable to participants when provided as a universal program. Providing depression prevention programs universally in schools has clear advantages: All students are reached, students are not stigmatized through participation, and interventions can provide a gateway for students with more severe problems to access specialized help. However, our findings suggest that more effective dissemination strategies are needed before universal programs like PRP are rolled out. Given the cost of universal programs, more evidence is needed that they provide value for the money and effort involved.
1 This project was intended to be a scaled-up, real-world intervention, trialing a program that had previously only been implemented in small samples and with high levels of control from the developers. To truly reflect real-world conditions, the program must also be sustainable. Flying staff to the United States for training is not a sustainable feature, and all subsequent training has been conducted in the United Kingdom. However, there is no difference in the training materials or hours of training received in this first year of implementation and in subsequent years, and the decision to site the original training in the United States was due to financial reasons—unusually favorable exchange rates made this the cheaper option. It therefore seems reasonable to believe that the first year of training was very similar to that received once the program became embedded in subsequent years, and as evidence of the practicality and sustainability of the intervention, there are now 85 schools teaching it in the United Kingdom, with over 800 teachers trained at 10 training courses. At least 250 of these teachers will have had their places funded entirely by the schools they work for, with the remainder being funded by some combination of school and LA funding. This demonstrates that schools and LAs are able and willing to provide the financial backing for the program.
2 Excluding observations without this measure does not change the results we obtain.
3 Note that for students in UKRP groups who completed the curriculum earlier in the year, the 1-year follow-up point would take place more than 1 year after postintervention. Thus, 1-year follow-up actually represents time periods of 12–16 months follow-up, and 2-year follow-up 24–30 months. We control for month of survey to take account of these differences.